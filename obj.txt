Project Overview
This project aims to develop a robust Python-based command-line application that leverages GPT for both code generation and learning facilitation. The application is designed to operate locally on the client side without relying on external frameworks or backend services. It targets users who wish to delve deeply into specific fields, offering comprehensive code generation capabilities and personalized learning experiences.

Core Components
1. Objective Classification
Purpose:
Determine whether the user's objective pertains to code generation or learning.

Implementation Details:

Classification Mechanism: Utilize the existing gpt_interact function to classify objectives. If a simple word dictionary proves insufficient, leverage GPT's capabilities for more nuanced classification.
Categories:
Code Generation
Learning
2. Dynamic Clarifying Questions
Purpose:
Generate tailored clarifying questions based on the classified objective to better understand the user's specific needs and goals.

Implementation Details:

Clarifying Questions Generator: Develop a module that leverages gpt_interact to produce at least four comprehensive and appropriate questions tailored to the objective type.
Question Types:
For Code Generation:
Specifics about the current objective.
Desired features.
Clarification of potential ambiguities.
Additional functional requirements.
For Learning Objectives:
Current knowledge level.
Specific topics of interest.
Preferred learning style.
Identification of challenging themes.
3. Orchestrator and Prompt Management
Purpose:
Manage the interaction flow, adapt prompts based on user responses, and handle sub-task generation to ensure seamless and relevant AI interactions.

Implementation Details:

Orchestrator Logic:
Manage AI interactions based solely on initial user inputs.
Allow GPT to handle task clarification and progression without requiring constant user supervision.
Prompt Templates:
Separate Templates: Design distinct prompt templates for each objective type (code generation and learning) to enhance interaction quality.
Adaptation Mechanism: Implement logic to modify prompts based on user responses and system understanding.
Sub-task Generation:
Break down user objectives into actionable sub-tasks.
Ensure that the current level of user interaction remains concise and sufficient.
4. Error Handling and Timeouts
Purpose:
Ensure smooth execution by managing errors and handling potential delays or unresponsive AI models gracefully.

Implementation Details:

Robust Error Management: Implement comprehensive error handling mechanisms for interactions and AI responses.
Timeout Mechanisms: Ensure the system can gracefully handle delays or unresponsive scenarios without crashing or freezing.
Graceful Degradation: Omit or forget unrelated tasks if errors occur, maintaining the focus on the primary objective.
5. User Experience Enhancements
Purpose:
Provide an intuitive and user-friendly experience, ensuring ease of use even for individuals with minimal programming knowledge.

Implementation Details:

Clear Instructions: Offer straightforward guidance at each interaction stage.
Feedback Mechanisms: Provide real-time feedback to inform users of the system's status and actions.
Intuitive Interactions: Design the command-line interface to be straightforward and easy to navigate.
Additional Enhancements:
Prompt Customization: Allow users to customize prompt preferences to better suit their individual needs.
Session Management: Enable users to save and resume sessions, facilitating continuous workflows.
Progress Indicators: Display progress bars or indicators during long-running tasks to keep users informed.
Help and Documentation: Incorporate accessible help commands and comprehensive documentation within the application.
Accessibility Features: Ensure the application is accessible to users with disabilities by supporting keyboard navigation and screen readers.
The project code:
import pychrome
import os
import sys
import time
import json
import subprocess
import argparse
from datetime import datetime
import shutil
import tempfile

# Global variables to store tabs
browser = None
tabs = {}
is_first_call = True

def is_chrome_running_in_debug_mode():
    # Check if Chrome is running in debug mode
    try:
        browser = pychrome.Browser(url="http://127.0.0.1:9222")
        browser.list_tab()
        return True
    except Exception:
        return False

user_data_dir = ""

def start_chrome_in_debug_mode():
    # Attempt to start Chrome in debug mode automatically
    chrome_paths = [
        r"C:\Program Files\Google\Chrome\Application\chrome.exe",
        r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
        r"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
        r"/usr/bin/google-chrome",
        r"/usr/bin/chromium-browser",
    ]

    chrome_path = next((path for path in chrome_paths if os.path.exists(path)), None)

    if not chrome_path:
        sys.exit("Google Chrome executable not found.")

    try:
        subprocess.Popen([
            chrome_path,
            "--remote-debugging-port=9222",
            "--no-first-run",
            "--no-default-browser-check",
            "--disable-default-apps",
            "--disable-popup-blocking",
            "--disable-extensions",
        ])
        time.sleep(2)  # Wait for Chrome to start
    except Exception as e:
        sys.exit(f"Failed to start Chrome in debug mode: {e}")

def initialize_browser():
    global browser, tabs
    browser = pychrome.Browser(url="http://127.0.0.1:9222")

    # Close any existing tabs
    existing_tabs = browser.list_tab()
    for tab in existing_tabs:
        browser.close_tab(tab)

    # URLs for each model
    urls = {
        "o1-preview": "https://chat.openai.com/?model=o1-preview",
        "o1-mini": "https://chat.openai.com/?model=o1-mini",
        "GPTo": "https://chat.openai.com/?model=GPTo",
    }
    # Open tabs for each model
    for model_name, url in urls.items():
        tab = browser.new_tab()
        tab.start()
        tab.Network.enable()
        tab.Page.enable()
        tab.Runtime.enable()
        tab.DOM.enable()
        tab.Page.navigate(url=url)
        # Wait for the page to load
        time.sleep(2)
        tabs[model_name] = tab

    # Check if login is required
    current_url = tabs["o1-preview"].Runtime.evaluate(
        expression="window.location.href"
    )["result"].get("value", "")
    if "login" in current_url or "auth0" in current_url:
        input("Please log in to ChatGPT in the opened browser tabs. After logging in, press Enter here to continue...")

def wait_for_selector(tab):
    result = tab.Runtime.evaluate(
        expression=f"document.querySelector('#prompt-textarea') !== null"
    )["result"].get("value", False)
    while not result:
        time.sleep(0.5)
        result = tab.Runtime.evaluate(
            expression=f"document.querySelector('#prompt-textarea') !== null"
        )["result"].get("value", False)

def gpt_interact(tab, prompt, update_interval=4, timeout=120):
    # Wait for the prompt textarea to be available
    wait_for_selector(tab)

    # Insert the prompt and submit
    browser.activate_tab(tab)
    tab.Runtime.evaluate(
        expression="document.querySelector('#prompt-textarea').focus()"
    )
    tab.call_method("Input.insertText", text=prompt)
    tab.call_method("Input.dispatchKeyEvent", type="keyDown", key="Enter", code="Enter", text="\r")
    tab.call_method("Input.dispatchKeyEvent", type="keyUp", key="Enter", code="Enter", text="\r")

    # Retrieve the response
    previous_text = ""
    start_time = time.time()
    while True:
        # JavaScript to check if the assistant has responded
        check_response_js = """
        (() => {
            const messages = document.querySelectorAll('div[class*="markdown"]');
            const lastMessage = messages[messages.length - 1];
            if (lastMessage) {
                return lastMessage.textContent.trim();
            }
            return null;
        })();
        """
        result = tab.Runtime.evaluate(expression=check_response_js)
        response_text = result.get("result", {}).get("value", None)
        if response_text:
            if previous_text == response_text:
                return response_text
            previous_text = response_text
        elapsed_time = time.time() - start_time
        if elapsed_time > timeout:
          raise TimeoutError("Waiting for response timed out.")
        else:
            time.sleep(update_interval)  # Check every n seconds

def gpt_orchestrator(objective):
    global is_first_call

    # Construct the prompt
    if is_first_call:
        prompt = (
            f"Objective: {objective}\n\n"
            f"Break down the objective into a list of small but important and meaningful sub-tasks to achieve the goal."
        )
        is_first_call = False
    else:
        prompt = (
            f"Objective: {objective}\n"
            "Identify the next small but important sub-task that needs to be done. Include short dictionary-like summary of context, previous completed sub-task, and if required add clarifications, and generate a concise, well-detailed prompt for a sub-agent to execute the task."
            "IF AND ONLY IF ALL SUB-TASKS ARE FINISHED, include 'The main task is complete:' at the beginning."
        )

    # Use the 'o1-mini' model tab
    tab = tabs.get("o1-mini")
    if tab is None:
        return ""

    # Interact with GPT
    try:
        response_text = gpt_interact(tab, prompt)
    except TimeoutError as e:
        response_text = ""

    return response_text

def user_edit_gpt_tasks(gpt_result):
    # Prompt the user to edit the result
    user_input_lines = []
    print("GPT Generated Result:")
    print(gpt_result)
    print("Edit the result if necessary. Submit an empty line to finish editing.")
    try:
        while True:
            line = input()
            if line == '':
                break
            user_input_lines.append(line)
    except KeyboardInterrupt:
        user_input = gpt_result
    else:
        user_input = '\n'.join(user_input_lines)

    # If the user doesn't provide any input, use the original GPT result
    if not user_input.strip():
        user_input = gpt_result

    # Send the user's input to the 'o1-mini' GPT model
    tab = tabs.get("o1-mini")
    if tab is None:
        return ""
    prompt = (
        f"Approved tasks:\n{user_input}\n"
        "Use these tasks as a reference for generating further sub-tasks."
    )

    # Interact with GPT
    try:
        response_text = gpt_interact(tab, prompt)
    except TimeoutError as e:
        response_text = ""

    return response_text

def gpt_sub_agent(sub_task_prompt):
    # Use the 'GPTo' model tab
    tab = tabs.get("GPTo")
    if tab is None:
        return ""
    sub_task_prompt += (
        "\nPlease execute the sub-task as specified. Ensure all requirements are met and provide detailed results. "
        "If there are any missing elements or if the task cannot be completed without additional context, provide suggestions or next steps."
    )
    # Interact with GPT
    try:
        response_text = gpt_interact(tab, sub_task_prompt)
    except TimeoutError as e:
        response_text = ""

    return response_text

def gpt_refine(objective):
    # Construct the prompt
    prompt = (
        f"Objective: {objective}\n\n"
        "Refine the sub-task results into a cohesive final output. Add any missing information."
        "For coding projects, provide the following if applicable:\n"
        "1. Project Name: A concise name (max 20 characters).\n"
        "2. Folder Structure: Provide as a JSON object wrapped in <folder_structure> tags.\n"
        "3. Code Files: For each code file, include the filename and code enclosed in triple backticks."
    )

    # Use the 'o1-preview' model tab
    tab = tabs.get("o1-mini")

    # Interact with GPT
    try:
        response_text = gpt_interact(tab, prompt, 15)
    except TimeoutError as e:
        response_text = ""

    return response_text

def main():
    parser = argparse.ArgumentParser(description="GPT Assistant Application")
    parser.add_argument('-o', '--objective', type=str, help='Your objective or the path to a file containing it')
    args = parser.parse_args()

    if not args.objective:
        user_input = input("Your objective or the path to a file containing it: ")
    else:
        user_input = args.objective

    # Check if the input is a file path
    if os.path.isfile(user_input):
        try:
            with open(user_input, 'r') as file:
                objective = file.read().strip()
        except Exception as e:
            sys.exit(f"An error occurred while reading the file: {e}")
    else:
        objective = user_input

    if not is_chrome_running_in_debug_mode():
        start_chrome_in_debug_mode()

    # Initialize the browser tabs
    initialize_browser()
    # Clear the file content at the start of each run
    with open('gpt_all_context.txt', 'w', encoding='utf-8'):
        pass  # This opens the file in write mode and immediately closes it, clearing its contents
    # Open the file in append mode
    with open('gpt_all_context.txt', 'a', encoding='utf-8') as file:
        # Main loop to orchestrate tasks until completion
        file.write(objective + '\n')  # Write initial objective
        while True:
            # Call the orchestrator with the objective
            if is_first_call:
                gpt_tasks = gpt_orchestrator(objective)
                gpt_tasks = user_edit_gpt_tasks(gpt_tasks)
                file.write(gpt_tasks + '\n')  # Write final result
                gpt_result = gpt_orchestrator(gpt_tasks)
            else:
                gpt_result = gpt_orchestrator(objective)
            if "The main task is complete:" in gpt_result:
                objective = gpt_result.replace("The main task is complete:", "").strip()
                break
            else:
                # Execute the sub-task using the GPT sub-agent
                sub_task_result = gpt_sub_agent(gpt_result)
                # Update the objective with the sub-task result for the next iteration
                objective = sub_task_result
                time.sleep(1)
                # Write the updated objective to the file
                file.write(objective + '\n')
        with open('gpt_all_context.txt', 'r', encoding='utf-8') as file:
            gpt_all_context = file.read()
    # Refine the final output using the GPT refine function
    refined_output = gpt_refine(gpt_all_context)

    # Write the refined output to a file with a timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"output_{timestamp}.md"
    with open(output_filename, "w", encoding='utf-8') as file:
        file.write(refined_output)

if __name__ == "__main__":
    main()